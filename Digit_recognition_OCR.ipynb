{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ZGOZJBCIcThO"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/klugenik/klugenik-Personal-Rep/blob/main/Digit_recognition_OCR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **OCR-instructions**"
      ],
      "metadata": {
        "id": "ZGOZJBCIcThO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Abstract**\n",
        "\n",
        "The OCR approach was utilized for the recognition and extraction of numerical readings from electricity meter images. EasyOCR was chosen over Keras and Tesseract due to several key advantages: its user-friendly API that facilitates implementation, its reduced complexity by offering pre-trained models for immediate use (which is particularly beneficial for companies), its high accuracy and robustness in digit recognition across diverse conditions and fonts, its superior performance with non-standard fonts, and its seamless integration with widely-used Python libraries such as OpenCV and Matplotlib, enabling efficient processing and visualization of results.\n",
        "\n",
        "*Important: Before executing the Python code, it is essential to upload the images 'meter0001.jpg' and 'meter0002.jpg' to the Google Colab environment. *kursiver Text*"
      ],
      "metadata": {
        "id": "T7lvYpk9bBDs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **OCR-model**"
      ],
      "metadata": {
        "id": "bxt_iFWXJMkj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Installation**\n",
        "\n",
        "The installation commands facilitate the setup of essential libraries crucial for developing an Optical Character Recognition (OCR) model tailored to recognize digits from images of electricity meters.\n",
        "\n",
        "Firstly, *'opencv-python-headless'* is installed to provide a streamlined version of OpenCV, optimized for server environments or systems without graphical interfaces. This version supports a range of computer vision tasks such as image reading, processing, and feature detection, pivotal for enhancing and analyzing meter images without the need for graphical output.\n",
        "\n",
        "Next, *'easyocr'* is installed, specializing in text extraction from images. This library supports multilingual OCR capabilities and employs efficient algorithms to accurately recognize text, including numerical digits, across diverse environmental conditions. It integrates seamlessly into the project to facilitate the extraction of meter readings from captured images, contributing to the overall functionality of the OCR solution.\n",
        "\n",
        "Finally, *'matplotlib'* is installed to provide comprehensive visualization tools. As a versatile plotting library, matplotlib enables the creation of static, animated, and interactive visualizations. Its integration ensures the project can visually represent processed images, annotate detected digits, and present OCR results in a clear and interpretable manner. Together, these installations establish a robust environment for developing and evaluating an OCR model designed specifically for digit recognition in electricity meter images."
      ],
      "metadata": {
        "id": "1lZmAXaKJXoZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Installation of OpenCV\n",
        "!pip install opencv-python-headless\n",
        "\n",
        "# Installation of EasyOCR\n",
        "!pip install easyocr\n",
        "\n",
        "# Installation of Matplotlib\n",
        "!pip install matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "U-GAulu-JhBZ",
        "outputId": "5242a4a5-2740-4f25-b49c-0c409f239fd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python-headless) (1.25.2)\n",
            "Requirement already satisfied: easyocr in /usr/local/lib/python3.10/dist-packages (1.7.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from easyocr) (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.18.1+cu121)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from easyocr) (4.10.0.84)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.11.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.25.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from easyocr) (9.4.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.19.3)\n",
            "Requirement already satisfied: python-bidi in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.5.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from easyocr) (6.0.1)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.10/dist-packages (from easyocr) (2.0.5)\n",
            "Requirement already satisfied: pyclipper in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.3.0.post5)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.11.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->easyocr) (12.5.82)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (2024.7.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (1.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (24.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->easyocr) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->easyocr) (1.3.0)\n",
            "Requirement already satisfied: python-bidi in /usr/local/lib/python3.10/dist-packages (0.5.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing Libraries**\n",
        "\n",
        "The essential libaries required  in this step are imported for developing an Optical Character Recognition (OCR) model aimed at digit recognition in electricity meter images.\n",
        "\n",
        "*'Cv2 (OpenCV)'* is imported to handle various computer vision tasks such as image reading, manipulation, and processing, which are foundational for enhancing image quality and extracting relevant features from meter images.\n",
        "\n",
        "*'Easyocr'* is imported as a specialized OCR library designed to extract text from images. It supports multiple languages and provides algorithms optimized for accurate character recognition, specifically focusing on digit identification from diverse image backgrounds and conditions.\n",
        "\n",
        "*'matplotlib.pyplot'* is imported to facilitate data visualization tasks, enabling the generation of graphical outputs that aid in visualizing processed images, annotating recognized digits, and presenting OCR results. This library plays a crucial role in visual feedback and evaluation of the OCR model's performance.\n",
        "\n",
        "Lastly, *'os'* is imported to interact with the operating system, allowing for file management tasks such as navigating directories, accessing image files, and ensuring compatibility across different operating environments. Together, these libraries establish a comprehensive framework necessary for implementing and evaluating an OCR solution tailored for digit recognition in electricity meter images."
      ],
      "metadata": {
        "id": "XkbVAiqKJotv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing libraries for image processing, OCR, visualization, and operating system tasks\n",
        "import cv2  # Library for computer vision tasks\n",
        "import easyocr  # Optical Character Recognition (OCR) library\n",
        "import matplotlib.pyplot as plt  # Visualization library\n",
        "import os  # Library for interacting with the operating system"
      ],
      "metadata": {
        "id": "buLApCEPJz5I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "945e03c0-ee8d-4478-879e-3ebb92d5af84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'bidi.algorithm'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-cd133b49a5f1>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Importing libraries for image processing, OCR, visualization, and operating system tasks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m  \u001b[0;31m# Library for computer vision tasks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0measyocr\u001b[0m  \u001b[0;31m# Optical Character Recognition (OCR) library\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m  \u001b[0;31m# Visualization library\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/easyocr/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0measyocr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mReader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'1.7.1'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/easyocr/easyocr.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                    \u001b[0mreformat_input_batched\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerge_to_free\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbidi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_display\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'bidi.algorithm'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading OCR Model**\n",
        "\n",
        "This step initializes an Optical Character Recognition (OCR) model by loading the OCR model with English language support. EasyOCR, is a robust OCR library and designed to extract text from images efficiently. By specifying ['en'], the model is tailored to recognize and process text in English. This setup is crucial for accurately identifying and interpreting digits and characters in images, such as in our exmample those from electricity meters. This initialization prepares the model for subsequent text recognition tasks, ensuring it is optimized for the specified language, thus enhancing its accuracy and reliability in extracting textual information from images.\n"
      ],
      "metadata": {
        "id": "rFI08kHSJ3fA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the OCR model with English language support\n",
        "reader = easyocr.Reader(['en'])"
      ],
      "metadata": {
        "id": "ZbaGqcTFJ6zL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining Image Files**\n",
        "\n",
        "This step is fundamental in organizing and managing the image files that will be used in the digit extraction process, ensuring a structured and efficient workflow, by initializing a list named image_files which contains the filenames of images, specifically 'meter0001.jpg' and 'meter0002.jpg'. These filenames correspond to images of electricity meters. By defining this list, the code prepares for the systematic access and processing of each image in subsequent operations. The list serves as a reference point, enabling the code to iterate through each image file, read the images, and perform OCR (Optical Character Recognition) to extract digits."
      ],
      "metadata": {
        "id": "e5Q7CQ08J92a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List of image filenames that should be extracted for digit recognition\n",
        "image_files = [\n",
        "    'meter0001.jpg', 'meter0002.jpg'\n",
        "]"
      ],
      "metadata": {
        "id": "tHWq296lKGAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining Digit Positions**\n",
        "\n",
        "In the following step a dictionary named positions is established, with each key representing an image filename and each corresponding value being a list of tuples. These tuples contain the coordinates (x, y, width, height) that define the regions within the respective images where digits are located. For 'meter0001.jpg' and 'meter0002.jpg', the coordinates specify the precise locations and dimensions of regions of interest (ROIs), indicating where the digits are expected to be found. This facilitates targeted image processing and analysis operations on these specific regions."
      ],
      "metadata": {
        "id": "4vB1B779KIH0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary defining the exact positions (x, y, width, height) of digits in each image\n",
        "positions = {\n",
        "'meter0001.jpg': [(9, 13, 84, 146), (99, 13, 76, 144,), (178, 13, 77, 143,), (261, 13, 77, 143,), (350, 17, 66, 136,)],\n",
        "'meter0002.jpg': [(6, 7, 49, 92), (60, 7, 49, 91), (113, 5, 58, 92,), (174, 5, 50, 92,), (229, 6, 48, 91,)]\n",
        "}"
      ],
      "metadata": {
        "id": "BPl2W0bBKL_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Setting Image Folder Path**\n",
        "\n",
        "Even if the images are already manually loaded in a former step, this path serves to organize and ensure that the images are accessible and correctly loaded.The variable image_folder is defined and the string '/content/' assigned (varies between storage locations). The purpose of this assignment is to specify the directory path where the image files required for further processing are located. By setting this variable, the code ensures a consistent reference point for accessing these images, facilitating file operations such as reading and writing."
      ],
      "metadata": {
        "id": "pbTKlHbhCtUv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory path for the images\n",
        "image_folder = '/content/'  # The image path can vary due to folder location"
      ],
      "metadata": {
        "id": "WuupjxTKCto3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining function for Executing Optical Character Recognition (OCR) and Visualizing Detected Text in Image Regions**\n",
        "\n",
        "The function process_image(image_filename, positions) in this step is used to perform Optical Character Recognition (OCR) on specified regions of an input image and display the results. The function begins by reading the image from the specified filename using cv2.imread. It then verifies if the image was successfully loaded, raising a FileNotFoundError if the image could not be loaded. Once the image is confirmed to be loaded, it is displayed using matplotlib, with the color space converted from BGR to RGB for correct visualization.\n",
        "\n",
        "The function iterates over each position in the provided positions list, which contains the coordinates and dimensions of regions of interest (ROIs) within the image. For each position, it extracts the corresponding ROI from the image. OCR is then applied to the extracted ROI using the reader.readtext method, which returns the detected text and its coordinates within the ROI.\n",
        "\n",
        "For each detected text result, the function calculates the absolute coordinates of the detected text in the context of the original image by adjusting the coordinates relative to the ROI's position. It also retrieves the detected text string and the confidence level of the detection. These results are then displayed on the image by plotting the bounding box of the detected text in red and annotating it with the detected text and its confidence level. Additionally, the detected text and confidence level are printed to the console.\n",
        "\n",
        "Finally, the function turns off the axis display using plt.axis('off') and shows the annotated image with plt.show(), thus completing the visualization of the OCR results."
      ],
      "metadata": {
        "id": "iBEZcaJEKSu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to perform OCR and display the results\n",
        "def process_image(image_filename, positions):\n",
        "    # Read image\n",
        "    img = cv2.imread(image_filename)\n",
        "\n",
        "    # Make sure the image has loaded\n",
        "    if img is None:\n",
        "        raise FileNotFoundError(f\"Bild konnte nicht geladen werden: {image_filename}\")\n",
        "\n",
        "    # Show image\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "    for idx, pos in enumerate(positions):\n",
        "        x, y, w, h = pos\n",
        "        # Cut out the area of ​​interest\n",
        "        roi = img[y:y+h, x:x+w]\n",
        "\n",
        "        # Apply OCR to the cutout area\n",
        "        results = reader.readtext(roi)\n",
        "\n",
        "        for res in results:\n",
        "            # Coordinates of the recognized text relative to the ROI\n",
        "            (xr1, yr1), (xr2, yr2), (xr3, yr3), (xr4, yr4) = res[0]\n",
        "            # Absolute coordinates in the original image\n",
        "            x1, y1 = x + xr1, y + yr1\n",
        "            x2, y2 = x + xr2, y + yr2\n",
        "            x3, y3 = x + xr3, y + yr3\n",
        "            x4, y4 = x + xr4, y + yr4\n",
        "            # Text and confidence of recognition\n",
        "            det, conf = res[1], res[2]\n",
        "            # View results\n",
        "            plt.plot([x1, x2, x3, x4, x1], [y1, y2, y3, y4, y1], 'r-')\n",
        "            plt.text(x1, y1 - 10, f'{det} [{round(conf, 2)}]', color='red', fontsize=12)\n",
        "            print(f'Digit {idx+1}: Text: {det}, Konfidenz: {conf:.2f}')\n",
        "\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "GqUr521TKWu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Iterating Over Image Files and processing**\n",
        "\n",
        "This step involves the iterative processing of multiple images (meter0001.jpg and meter0002.jpg). For each image file in the list, the complete path to the image is generated by concatenating the directory path (image_folder) with the image filename (image_file). This path is then used to load and process the specific image. A message is printed to the console to indicate which image is being processed, thereby providing clarity on the current operation. Subsequently, the process_image function is called with the constructed image path and the corresponding positional data retrieved from the positions dictionary for the specific image file. This procedure ensures that each image is processed according to its designated regions of interest, as defined by the positional data."
      ],
      "metadata": {
        "id": "aan7fggVKcXI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate through the image files and process them\n",
        "for image_file in image_files:\n",
        "    image_path = os.path.join(image_folder, image_file)\n",
        "    print(f\"Processing Image: {image_path}\")\n",
        "    process_image(image_path, positions[image_file])"
      ],
      "metadata": {
        "id": "-J4_eSTNKgx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Image preprocessing - deblurring and denoising**"
      ],
      "metadata": {
        "id": "hwi8gwdUL5h0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Installation**\n",
        "\n",
        "The installation commands facilitate the setup of essential libraries crucial for developing an Optical Character Recognition (OCR) model tailored to recognize digits from images of electricity meters.\n",
        "\n",
        "Firstly, *'opencv-python-headless'* is installed to provide a streamlined version of OpenCV, optimized for server environments or systems without graphical interfaces. This version supports a range of computer vision tasks such as image reading, processing, and feature detection, pivotal for enhancing and analyzing meter images without the need for graphical output.\n",
        "\n",
        "Next, *'easyocr'* is installed, specializing in text extraction from images. This library supports multilingual OCR capabilities and employs efficient algorithms to accurately recognize text, including numerical digits, across diverse environmental conditions. It integrates seamlessly into the project to facilitate the extraction of meter readings from captured images, contributing to the overall functionality of the OCR solution.\n",
        "\n",
        "Finally, *'matplotlib'* is installed to provide comprehensive visualization tools. As a versatile plotting library, matplotlib enables the creation of static, animated, and interactive visualizations. Its integration ensures the project can visually represent processed images, annotate detected digits, and present OCR results in a clear and interpretable manner. Together, these installations establish a robust environment for developing and evaluating an OCR model designed specifically for digit recognition in electricity meter images."
      ],
      "metadata": {
        "id": "MgQ0Q1EJL_2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Installation of OpenCV\n",
        "!pip install opencv-python-headless\n",
        "\n",
        "# Installation of EasyOCR\n",
        "!pip install easyocr\n",
        "\n",
        "# Installation of Matplotlib\n",
        "!pip install matplotlib"
      ],
      "metadata": {
        "collapsed": true,
        "id": "kWz1Ta2WMi5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing Libraries**\n",
        "\n",
        "The essential libaries required  in this step are imported for developing an Optical Character Recognition (OCR) model aimed at digit recognition in electricity meter images.\n",
        "\n",
        "*'Cv2 (OpenCV)'* is imported to handle various computer vision tasks such as image reading, manipulation, and processing, which are foundational for enhancing image quality and extracting relevant features from meter images.\n",
        "\n",
        "*'Easyocr'* is imported as a specialized OCR library designed to extract text from images. It supports multiple languages and provides algorithms optimized for accurate character recognition, specifically focusing on digit identification from diverse image backgrounds and conditions.\n",
        "\n",
        "*'matplotlib.pyplot'* is imported to facilitate data visualization tasks, enabling the generation of graphical outputs that aid in visualizing processed images, annotating recognized digits, and presenting OCR results. This library plays a crucial role in visual feedback and evaluation of the OCR model's performance.\n",
        "\n",
        "Lastly, *'os'* is imported to interact with the operating system, allowing for file management tasks such as navigating directories, accessing image files, and ensuring compatibility across different operating environments. Together, these libraries establish a comprehensive framework necessary for implementing and evaluating an OCR solution tailored for digit recognition in electricity meter images."
      ],
      "metadata": {
        "id": "CsUAt-QSMt8r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing libraries for image processing, OCR, visualization, and operating system tasks\n",
        "import cv2  # Library for computer vision tasks\n",
        "import easyocr  # Optical Character Recognition (OCR) library\n",
        "import matplotlib.pyplot as plt  # Visualization library\n",
        "import os  # Library for interacting with the operating system"
      ],
      "metadata": {
        "id": "3tMLttttNcSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading OCR Model**\n",
        "\n",
        "This step initializes an Optical Character Recognition (OCR) model by loading the OCR model with English language support. EasyOCR, is a robust OCR library and designed to extract text from images efficiently. By specifying ['en'], the model is tailored to recognize and process text in English. This setup is crucial for accurately identifying and interpreting digits and characters in images, such as in our exmample those from electricity meters. This initialization prepares the model for subsequent text recognition tasks, ensuring it is optimized for the specified language, thus enhancing its accuracy and reliability in extracting textual information from images."
      ],
      "metadata": {
        "id": "NAW9iKqRN16A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the OCR model with English language support\n",
        "reader = easyocr.Reader(['en'])"
      ],
      "metadata": {
        "id": "4Y0tTFM5OJOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining Image Files**\n",
        "\n",
        "This step is fundamental in organizing and managing the image files that will be used in the digit extraction process, ensuring a structured and efficient workflow, by initializing a list named image_files which contains the filenames of images, specifically 'meter0001.jpg' and 'meter0002.jpg'. These filenames correspond to images of electricity meters. By defining this list, the code prepares for the systematic access and processing of each image in subsequent operations. The list serves as a reference point, enabling the code to iterate through each image file, read the images, and perform OCR (Optical Character Recognition) to extract digits."
      ],
      "metadata": {
        "id": "TK7Km6l2OKkX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List of image filenames that should be extracted for digit recognition\n",
        "image_files = [\n",
        "    'meter0001.jpg', 'meter0002.jpg'\n",
        "]"
      ],
      "metadata": {
        "id": "95DLRnVlOavC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining Digit Positions**\n",
        "\n",
        "In the following step a dictionary named positions is established, with each key representing an image filename and each corresponding value being a list of tuples. These tuples contain the coordinates (x, y, width, height) that define the regions within the respective images where digits are located. For 'meter0001.jpg' and 'meter0002.jpg', the coordinates specify the precise locations and dimensions of regions of interest (ROIs), indicating where the digits are expected to be found. This facilitates targeted image processing and analysis operations on these specific regions."
      ],
      "metadata": {
        "id": "V8GYgzkInvKo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary defining the exact positions (x, y, width, height) of digits in each image\n",
        "positions = {\n",
        "    'meter0001.jpg': [(9, 13, 84, 146), (99, 13, 76, 144,), (178, 13, 77, 143,), (261, 13, 77, 143,), (350, 17, 66, 136,)],\n",
        "    'meter0002.jpg': [(6, 7, 49, 92), (60, 7, 49, 91), (113, 5, 58, 92,), (174, 5, 50, 92,), (229, 6, 48, 91,)]\n",
        "}\n"
      ],
      "metadata": {
        "id": "I9DPWERKnvgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Setting Image Folder Path**\n",
        "\n",
        "Even if the images are already manually loaded in a former step, this path serves to organize and ensure that the images are accessible and correctly loaded.The variable image_folder is defined and the string '/content/' assigned (varies between storage locations). The purpose of this assignment is to specify the directory path where the image files required for further processing are located. By setting this variable, the code ensures a consistent reference point for accessing these images, facilitating file operations such as reading and writing."
      ],
      "metadata": {
        "id": "RUg7Jun9DAQc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory path for the images\n",
        "image_folder = '/content/'  # The image path can vary due to folder location"
      ],
      "metadata": {
        "id": "uCfIHwlADAb0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining deblur_image function**\n",
        "\n",
        "The deblur_image function is designed to mitigate the effects of blurriness in an image. Initially, the function applies a Gaussian blur to the input image using cv2.GaussianBlur, which involves convolving the image with a Gaussian kernel of size 5x5. This operation creates a blurred version of the image. Subsequently, the function employs the cv2.addWeighted method to enhance the clarity of the original image by combining it with the blurred image. Specifically, the original image is weighted by a factor of 1.5, while the blurred image is weighted by a factor of -0.5. The resulting image, which is a linear combination of the original and blurred images, aims to reduce the appearance of blur and enhance the sharpness. The function then returns this processed image as the output."
      ],
      "metadata": {
        "id": "48AEGz_MOmm3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Blur reduction function\n",
        "def deblur_image(image):\n",
        "    blurred = cv2.GaussianBlur(image, (5, 5), 0)\n",
        "    deblurred = cv2.addWeighted(image, 1.5, blurred, -0.5, 0)\n",
        "    return deblurred"
      ],
      "metadata": {
        "id": "gxaysmDsOwKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dedining denoise_image function**\n",
        "\n",
        "The denoise_image function is designed to reduce noise in an image. It utilizes the cv2.fastNlMeansDenoisingColored method, which is an implementation of the Non-Local Means Denoising algorithm tailored for color images. This algorithm works by comparing patches within the image and averaging similar patches to suppress noise while preserving important image details. The parameters provided to this function include a h-value of 10, which controls the filter strength, and parameters for the template and search window sizes, set at 7 and 21 respectively. The resulting output is a denoised image, which is returned by the function."
      ],
      "metadata": {
        "id": "khxK3y7-O6BB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Noise reduction function\n",
        "def denoise_image(image):\n",
        "    denoised = cv2.fastNlMeansDenoisingColored(image, None, 10, 10, 7, 21)\n",
        "    return denoised"
      ],
      "metadata": {
        "id": "HaDu_B6gPFk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining function for Executing Optical Character Recognition (OCR) and Visualizing Detected Text in Image Regions**\n",
        "\n",
        "The process_image function is used to perform Optical Character Recognition (OCR) on specified regions of an image and display the results. Initially, the function reads the image from the file path provided using cv2.imread. It then checks whether the image has been successfully loaded; if not, it raises a FileNotFoundError indicating the failure to load the specified image.\n",
        "\n",
        "Upon successful loading, the function proceeds to visualize the image by converting its color space from BGR to RGB and displaying it using matplotlib. The function iterates through a list of positions, each defining a rectangular region of interest (ROI) within the image. For each position, it extracts the corresponding ROI and applies the OCR process to this segment using reader.readtext, which detects and reads text within the ROI.\n",
        "\n",
        "The OCR results include the bounding box coordinates of the detected text within the ROI. These coordinates are adjusted to the absolute position in the original image by adding the ROI's coordinates. The detected text and its confidence level are then displayed on the image. Bounding boxes are drawn around the detected text using red lines, and the text, along with its confidence score, is annotated above the detected text.\n",
        "\n",
        "Finally, the function disables the axis labels and ticks with plt.axis('off') and shows the annotated image using plt.show(). This comprehensive approach ensures that the detected text and its location are clearly presented on the image."
      ],
      "metadata": {
        "id": "Sh-Tayd5PJJ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "62 / 5.000\n",
        "# Function to perform OCR and display the results\n",
        "def process_image(image_filename, positions):\n",
        "    # Read image\n",
        "    img = cv2.imread(image_filename)\n",
        "\n",
        "    # Make sure the image has loaded\n",
        "    if img is None:\n",
        "        raise FileNotFoundError(f\"Bild konnte nicht geladen werden: {image_filename}\")\n",
        "\n",
        "    # Image deblur and denoise\n",
        "    deblurred_img = deblur_image(img)\n",
        "    denoised_img = denoise_image(deblurred_img)\n",
        "\n",
        "    # Show image\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(cv2.cvtColor(denoised_img, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "    for idx, pos in enumerate(positions):\n",
        "        x, y, w, h = pos\n",
        "        # Cut out the area of ​​interest\n",
        "        roi = denoised_img[y:y+h, x:x+w]\n",
        "\n",
        "        # Apply OCR to the cutout area\n",
        "        results = reader.readtext(roi)\n",
        "\n",
        "        for res in results:\n",
        "            # Coordinates of the recognized text relative to the ROI\n",
        "            (xr1, yr1), (xr2, yr2), (xr3, yr3), (xr4, yr4) = res[0]\n",
        "            # Absolute coordinates in the original image\n",
        "            x1, y1 = x + xr1, y + yr1\n",
        "            x2, y2 = x + xr2, y + yr2\n",
        "            x3, y3 = x + xr3, y + yr3\n",
        "            x4, y4 = x + xr4, y + yr4\n",
        "            Text and confidence of recognition\n",
        "            det, conf = res[1], res[2]\n",
        "            # View results\n",
        "            plt.plot([x1, x2, x3, x4, x1], [y1, y2, y3, y4, y1], 'r-')\n",
        "            plt.text(x1, y1 - 10, f'{det} [{round(conf, 2)}]', color='red', fontsize=12)\n",
        "            print(f'Digit {idx+1}: Text: {det}, Konfidenz: {conf:.2f}')\n",
        "\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Xq-AaT-KPR_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Iterating Over Image Files and processing**\n",
        "\n",
        "This step involves the iterative processing of multiple images (meter0001.jpg and meter0002.jpg). For each image file in the list, the complete path to the image is generated by concatenating the directory path (image_folder) with the image filename (image_file). This path is then used to load and process the specific image. A message is printed to the console to indicate which image is being processed, thereby providing clarity on the current operation. Subsequently, the process_image function is called with the constructed image path and the corresponding positional data retrieved from the positions dictionary for the specific image file. This procedure ensures that each image is processed according to its designated regions of interest, as defined by the positional data."
      ],
      "metadata": {
        "id": "VNBrz0fNPYFe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate through the image files and process them\n",
        "for image_file in image_files:\n",
        "    image_path = os.path.join(image_folder, image_file)\n",
        "    print(f\"Verarbeite Bild: {image_path}\")\n",
        "    process_image(image_path, positions[image_file])"
      ],
      "metadata": {
        "id": "6esUNaYoPjlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Image preprocessing - black and white conversion**"
      ],
      "metadata": {
        "id": "reizPOuaSd4e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Installation**\n",
        "\n",
        "The installation commands facilitate the setup of essential libraries crucial for developing an Optical Character Recognition (OCR) model tailored to recognize digits from images of electricity meters.\n",
        "\n",
        "Firstly, *'opencv-python-headless'* is installed to provide a streamlined version of OpenCV, optimized for server environments or systems without graphical interfaces. This version supports a range of computer vision tasks such as image reading, processing, and feature detection, pivotal for enhancing and analyzing meter images without the need for graphical output.\n",
        "\n",
        "Next, *'easyocr'* is installed, specializing in text extraction from images. This library supports multilingual OCR capabilities and employs efficient algorithms to accurately recognize text, including numerical digits, across diverse environmental conditions. It integrates seamlessly into the project to facilitate the extraction of meter readings from captured images, contributing to the overall functionality of the OCR solution.\n",
        "\n",
        "Finally, *'matplotlib'* is installed to provide comprehensive visualization tools. As a versatile plotting library, matplotlib enables the creation of static, animated, and interactive visualizations. Its integration ensures the project can visually represent processed images, annotate detected digits, and present OCR results in a clear and interpretable manner. Together, these installations establish a robust environment for developing and evaluating an OCR model designed specifically for digit recognition in electricity meter images."
      ],
      "metadata": {
        "id": "OQNmmthUSj3_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Installation of OpenCV\n",
        "!pip install opencv-python-headless\n",
        "\n",
        "# Installation of EasyOCR\n",
        "!pip install easyocr\n",
        "\n",
        "# Installation of Matplotlib\n",
        "!pip install matplotlib"
      ],
      "metadata": {
        "collapsed": true,
        "id": "rXPBD2NaTaqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing Libraries**\n",
        "\n",
        "The essential libaries required  in this step are imported for developing an Optical Character Recognition (OCR) model aimed at digit recognition in electricity meter images.\n",
        "\n",
        "*'Cv2 (OpenCV)'* is imported to handle various computer vision tasks such as image reading, manipulation, and processing, which are foundational for enhancing image quality and extracting relevant features from meter images.\n",
        "\n",
        "*'Easyocr'* is imported as a specialized OCR library designed to extract text from images. It supports multiple languages and provides algorithms optimized for accurate character recognition, specifically focusing on digit identification from diverse image backgrounds and conditions.\n",
        "\n",
        "*'matplotlib.pyplot'* is imported to facilitate data visualization tasks, enabling the generation of graphical outputs that aid in visualizing processed images, annotating recognized digits, and presenting OCR results. This library plays a crucial role in visual feedback and evaluation of the OCR model's performance.\n",
        "\n",
        "Lastly, *'os'* is imported to interact with the operating system, allowing for file management tasks such as navigating directories, accessing image files, and ensuring compatibility across different operating environments. Together, these libraries establish a comprehensive framework necessary for implementing and evaluating an OCR solution tailored for digit recognition in electricity meter images."
      ],
      "metadata": {
        "id": "hsPPN7-kTaeC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing libraries for image processing, OCR, visualization, and operating system tasks\n",
        "import cv2  # Library for computer vision tasks\n",
        "import easyocr  # Optical Character Recognition (OCR) library\n",
        "import matplotlib.pyplot as plt  # Visualization library\n",
        "import os  # Library for interacting with the operating system"
      ],
      "metadata": {
        "id": "cquuWt9uTCZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading OCR Model**\n",
        "\n",
        "This step initializes an Optical Character Recognition (OCR) model by loading the OCR model with English language support. EasyOCR, is a robust OCR library and designed to extract text from images efficiently. By specifying ['en'], the model is tailored to recognize and process text in English. This setup is crucial for accurately identifying and interpreting digits and characters in images, such as in our exmample those from electricity meters. This initialization prepares the model for subsequent text recognition tasks, ensuring it is optimized for the specified language, thus enhancing its accuracy and reliability in extracting textual information from images."
      ],
      "metadata": {
        "id": "U1kyeaozTHDI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the OCR model with English language support\n",
        "reader = easyocr.Reader(['en'])"
      ],
      "metadata": {
        "id": "OrDATERrTHSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining Image Files**\n",
        "\n",
        "This step is fundamental in organizing and managing the image files that will be used in the digit extraction process, ensuring a structured and efficient workflow, by initializing a list named image_files which contains the filenames of images, specifically 'meter0001.jpg' and 'meter0002.jpg'. These filenames correspond to images of electricity meters. By defining this list, the code prepares for the systematic access and processing of each image in subsequent operations. The list serves as a reference point, enabling the code to iterate through each image file, read the images, and perform OCR (Optical Character Recognition) to extract digits."
      ],
      "metadata": {
        "id": "F3wr1WTVTI7W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List of image filenames that should be extracted for digit recognition\n",
        "image_files = [\n",
        "    'meter0001.jpg', 'meter0002.jpg'\n",
        "]"
      ],
      "metadata": {
        "id": "X6UQ8d6cTJJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining Digit Positions**\n",
        "\n",
        "In the following step a dictionary named positions is established, with each key representing an image filename and each corresponding value being a list of tuples. These tuples contain the coordinates (x, y, width, height) that define the regions within the respective images where digits are located. For 'meter0001.jpg' and 'meter0002.jpg', the coordinates specify the precise locations and dimensions of regions of interest (ROIs), indicating where the digits are expected to be found. This facilitates targeted image processing and analysis operations on these specific regions."
      ],
      "metadata": {
        "id": "cTUBpTlOoFxV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary defining the exact positions (x, y, width, height) of digits in each image\n",
        "positions = {\n",
        "'meter0001.jpg': [(9, 13, 84, 146), (99, 13, 76, 144,), (178, 13, 77, 143,), (261, 13, 77, 143,), (350, 17, 66, 136,)],\n",
        "'meter0002.jpg': [(6, 7, 49, 92), (60, 7, 49, 91), (113, 5, 58, 92,), (174, 5, 50, 92,), (229, 6, 48, 91,)]\n",
        "}"
      ],
      "metadata": {
        "id": "dWGGyrkEoF91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Setting Image Folder Path**\n",
        "\n",
        "Even if the images are already manually loaded in a former step, this path serves to organize and ensure that the images are accessible and correctly loaded.The variable image_folder is defined and the string '/content/' assigned (varies between storage locations). The purpose of this assignment is to specify the directory path where the image files required for further processing are located. By setting this variable, the code ensures a consistent reference point for accessing these images, facilitating file operations such as reading and writing."
      ],
      "metadata": {
        "id": "1Q8D33yeDGKD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory path for the images\n",
        "image_folder = '/content/'  # The image path can vary due to folder location"
      ],
      "metadata": {
        "id": "HRmJiknSDGTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining function for Executing Optical Character Recognition (OCR) and Visualizing Detected Text in Image Regions**\n",
        "\n",
        "In this step the process_image function is used to apply Optical Character Recognition (OCR) on an image and display the results, incorporating several preprocessing steps to enhance text detection. Initially, the function reads the image from the specified file path using cv2.imread and checks for successful loading, raising a FileNotFoundError if the image cannot be loaded.\n",
        "\n",
        "Following the successful loading of the image, the function converts the image to grayscale using cv2.cvtColor, which simplifies the image by removing color information. This grayscale image is then subjected to a binarization process through cv2.threshold. In this step, pixel values are thresholded to create a binary image where pixels are either black or white. The binarization utilizes Otsu’s thresholding method to automatically determine the optimal threshold value.\n",
        "\n",
        "The function then visualizes the binary image using matplotlib, setting the colormap to grayscale to accurately represent the binary image. It iterates over the specified positions, each defining a rectangular region of interest (ROI) within the binary image. For each ROI, the function extracts the relevant segment and performs OCR using reader.readtext to detect and read any text present within the ROI.\n",
        "\n",
        "The results of the OCR process include bounding box coordinates for the detected text. These coordinates are adjusted to reflect their positions in the context of the original image. The function then visualizes the detected text by drawing bounding boxes around the detected regions in red and annotating the text along with its confidence score on the image. Finally, the function disables axis labels and ticks using plt.axis('off') and displays the annotated image with plt.show(), thereby providing a clear view of the OCR results and their locations within the image."
      ],
      "metadata": {
        "id": "cLJq9_zbTPAH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to perform OCR and display the results\n",
        "def process_image(image_filename, positions):\n",
        "    # Read image\n",
        "    img = cv2.imread(image_filename)\n",
        "\n",
        "    # Make sure the image has loaded\n",
        "    if img is None:\n",
        "        raise FileNotFoundError(f\"Bild konnte nicht geladen werden: {image_filename}\")\n",
        "\n",
        "    # Convert image to grayscale\n",
        "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Binarize image (thresholding)\n",
        "    _, binary_img = cv2.threshold(gray_img, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
        "\n",
        "    # Show image\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(binary_img, cmap='gray')\n",
        "\n",
        "    for idx, pos in enumerate(positions):\n",
        "        x, y, w, h = pos\n",
        "        # Cut out the area of ​​interest\n",
        "        roi = binary_img[y:y+h, x:x+w]\n",
        "\n",
        "        # Apply OCR to the cutout area\n",
        "        results = reader.readtext(roi)\n",
        "\n",
        "        for res in results:\n",
        "            # Coordinates of the recognized text relative to the ROI\n",
        "            (xr1, yr1), (xr2, yr2), (xr3, yr3), (xr4, yr4) = res[0]\n",
        "            # Absolute coordinates in the original image\n",
        "            x1, y1 = x + xr1, y + yr1\n",
        "            x2, y2 = x + xr2, y + yr2\n",
        "            x3, y3 = x + xr3, y + yr3\n",
        "            x4, y4 = x + xr4, y + yr4\n",
        "            # Text and confidence of recognition\n",
        "            det, conf = res[1], res[2]\n",
        "            # View results\n",
        "            plt.plot([x1, x2, x3, x4, x1], [y1, y2, y3, y4, y1], 'r-')\n",
        "            plt.text(x1, y1 - 10, f'{det} [{round(conf, 2)}]', color='red', fontsize=12)\n",
        "            print(f'Digit {idx+1}: Text: {det}, Konfidenz: {conf:.2f}')\n",
        "\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "lj4tt69eTPIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Iterating Over Image Files and processing**\n",
        "\n",
        "This step involves the iterative processing of multiple images (meter0001.jpg and meter0002.jpg). For each image file in the list, the complete path to the image is generated by concatenating the directory path (image_folder) with the image filename (image_file). This path is then used to load and process the specific image. A message is printed to the console to indicate which image is being processed, thereby providing clarity on the current operation. Subsequently, the process_image function is called with the constructed image path and the corresponding positional data retrieved from the positions dictionary for the specific image file. This procedure ensures that each image is processed according to its designated regions of interest, as defined by the positional data."
      ],
      "metadata": {
        "id": "p9rxFuOETRc_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate through the image files and process them\n",
        "for image_file in image_files:\n",
        "    image_path = os.path.join(image_folder, image_file)\n",
        "    print(f\"Verarbeite Bild: {image_path}\")\n",
        "    process_image(image_path, positions[image_file])"
      ],
      "metadata": {
        "collapsed": true,
        "id": "j0vXKws0TRm1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Image preprocessing - grayscaling**"
      ],
      "metadata": {
        "id": "eU0kkEhAT5Ef"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Installation**\n",
        "\n",
        "The installation commands facilitate the setup of essential libraries crucial for developing an Optical Character Recognition (OCR) model tailored to recognize digits from images of electricity meters.\n",
        "\n",
        "Firstly, *'opencv-python-headless'* is installed to provide a streamlined version of OpenCV, optimized for server environments or systems without graphical interfaces. This version supports a range of computer vision tasks such as image reading, processing, and feature detection, pivotal for enhancing and analyzing meter images without the need for graphical output.\n",
        "\n",
        "Next, *'easyocr'* is installed, specializing in text extraction from images. This library supports multilingual OCR capabilities and employs efficient algorithms to accurately recognize text, including numerical digits, across diverse environmental conditions. It integrates seamlessly into the project to facilitate the extraction of meter readings from captured images, contributing to the overall functionality of the OCR solution.\n",
        "\n",
        "Finally, *'matplotlib'* is installed to provide comprehensive visualization tools. As a versatile plotting library, matplotlib enables the creation of static, animated, and interactive visualizations. Its integration ensures the project can visually represent processed images, annotate detected digits, and present OCR results in a clear and interpretable manner. Together, these installations establish a robust environment for developing and evaluating an OCR model designed specifically for digit recognition in electricity meter images."
      ],
      "metadata": {
        "id": "jM_qzscWT9k5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Installation of OpenCV\n",
        "!pip install opencv-python-headless\n",
        "\n",
        "# Installation of EasyOCR\n",
        "!pip install easyocr\n",
        "\n",
        "# Installation of Matplotlib\n",
        "!pip install matplotlib"
      ],
      "metadata": {
        "collapsed": true,
        "id": "lV6kTxYOUXC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing Libraries**\n",
        "\n",
        "The essential libaries required  in this step are imported for developing an Optical Character Recognition (OCR) model aimed at digit recognition in electricity meter images.\n",
        "\n",
        "*'Cv2 (OpenCV)'* is imported to handle various computer vision tasks such as image reading, manipulation, and processing, which are foundational for enhancing image quality and extracting relevant features from meter images.\n",
        "\n",
        "*'Easyocr'* is imported as a specialized OCR library designed to extract text from images. It supports multiple languages and provides algorithms optimized for accurate character recognition, specifically focusing on digit identification from diverse image backgrounds and conditions.\n",
        "\n",
        "*'matplotlib.pyplot'* is imported to facilitate data visualization tasks, enabling the generation of graphical outputs that aid in visualizing processed images, annotating recognized digits, and presenting OCR results. This library plays a crucial role in visual feedback and evaluation of the OCR model's performance.\n",
        "\n",
        "Lastly, *'os'* is imported to interact with the operating system, allowing for file management tasks such as navigating directories, accessing image files, and ensuring compatibility across different operating environments. Together, these libraries establish a comprehensive framework necessary for implementing and evaluating an OCR solution tailored for digit recognition in electricity meter images."
      ],
      "metadata": {
        "id": "JidU24fjUzbv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing libraries for image processing, OCR, visualization, and operating system tasks\n",
        "import cv2  # Library for computer vision tasks\n",
        "import easyocr  # Optical Character Recognition (OCR) library\n",
        "import matplotlib.pyplot as plt  # Visualization library\n",
        "import os  # Library for interacting with the operating system"
      ],
      "metadata": {
        "id": "P_WX8JhxU0la"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading OCR Model**\n",
        "\n",
        "This step initializes an Optical Character Recognition (OCR) model by loading the OCR model with English language support. EasyOCR, is a robust OCR library and designed to extract text from images efficiently. By specifying ['en'], the model is tailored to recognize and process text in English. This setup is crucial for accurately identifying and interpreting digits and characters in images, such as in our exmample those from electricity meters. This initialization prepares the model for subsequent text recognition tasks, ensuring it is optimized for the specified language, thus enhancing its accuracy and reliability in extracting textual information from images."
      ],
      "metadata": {
        "id": "09uToURzUbNC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the OCR model with English language support\n",
        "reader = easyocr.Reader(['en'])"
      ],
      "metadata": {
        "id": "NVq_xRPLUbec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining Image Files**\n",
        "\n",
        "This step is fundamental in organizing and managing the image files that will be used in the digit extraction process, ensuring a structured and efficient workflow, by initializing a list named image_files which contains the filenames of images, specifically 'meter0001.jpg' and 'meter0002.jpg'. These filenames correspond to images of electricity meters. By defining this list, the code prepares for the systematic access and processing of each image in subsequent operations. The list serves as a reference point, enabling the code to iterate through each image file, read the images, and perform OCR (Optical Character Recognition) to extract digits."
      ],
      "metadata": {
        "id": "ckR7ffv7Udwb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List of image filenames that should be extracted for digit recognition\n",
        "image_files = [\n",
        "    'meter0001.jpg', 'meter0002.jpg'\n",
        "]"
      ],
      "metadata": {
        "id": "XYKKM5noUd9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining Digit Positions**\n",
        "\n",
        "In the following step a dictionary named positions is established, with each key representing an image filename and each corresponding value being a list of tuples. These tuples contain the coordinates (x, y, width, height) that define the regions within the respective images where digits are located. For 'meter0001.jpg' and 'meter0002.jpg', the coordinates specify the precise locations and dimensions of regions of interest (ROIs), indicating where the digits are expected to be found. This facilitates targeted image processing and analysis operations on these specific regions."
      ],
      "metadata": {
        "id": "TzA6e3FioRgY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary defining the exact positions (x, y, width, height) of digits in each image\n",
        "positions = {\n",
        "'meter0001.jpg': [(9, 13, 84, 146), (99, 13, 76, 144,), (178, 13, 77, 143,), (261, 13, 77, 143,), (350, 17, 66, 136,)],\n",
        "'meter0002.jpg': [(6, 7, 49, 92), (60, 7, 49, 91), (113, 5, 58, 92,), (174, 5, 50, 92,), (229, 6, 48, 91,)]\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "dyUcxTdBoRsn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Setting Image Folder Path**\n",
        "\n",
        "Even if the images are already manually loaded in a former step, this path serves to organize and ensure that the images are accessible and correctly loaded.The variable image_folder is defined and the string '/content/' assigned (varies between storage locations). The purpose of this assignment is to specify the directory path where the image files required for further processing are located. By setting this variable, the code ensures a consistent reference point for accessing these images, facilitating file operations such as reading and writing."
      ],
      "metadata": {
        "id": "5vTPtX7yUqQT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory path for the images\n",
        "image_folder = '/content/'  # The image path can vary due to folder location"
      ],
      "metadata": {
        "id": "6xEDjrHxDNff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining function for Executing Optical Character Recognition (OCR) and Visualizing Detected Text in Image Regions**\n",
        "\n",
        "The process_image function in this step is designed to execute Optical Character Recognition (OCR) on specific regions of a grayscale image and to visualize the results. The process begins with reading the image from the specified file path using the cv2.imread function. The function then verifies that the image has been successfully loaded; if not, it raises a FileNotFoundError to indicate the failure to load the image.\n",
        "\n",
        "Upon successful loading, the image is converted to grayscale with the cv2.cvtColor function, which simplifies the image by removing color information and reducing it to shades of gray. This grayscale image is then displayed using matplotlib to provide a visual reference for the OCR results.\n",
        "\n",
        "The function iterates over a list of positions, where each position specifies a rectangular region of interest (ROI) within the image. For each position, it extracts the corresponding ROI from the grayscale image. The OCR process is applied to this ROI using the reader.readtext method, which identifies and reads any text present within this segment.\n",
        "\n",
        "The results from the OCR process include the coordinates of the detected text within the ROI. These coordinates are adjusted to reflect their positions in the context of the original image. The function then visualizes the OCR results by drawing bounding boxes around the detected text in red and annotating these boxes with the detected text and its confidence level. This information is also printed to the console for further reference.\n",
        "\n",
        "Finally, the function disables the display of axis labels and ticks using plt.axis('off'), and shows the annotated image with plt.show(). This comprehensive approach ensures that the detected text and its spatial location within the image are clearly presented."
      ],
      "metadata": {
        "id": "UB4xQ5StDM61"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to perform OCR and display the results\n",
        "def process_image(image_filename, positions):\n",
        "    # Read image\n",
        "    img = cv2.imread(image_filename)\n",
        "\n",
        "    # Make sure the image has loaded\n",
        "    if img is None:\n",
        "        raise FileNotFoundError(f\"Bild konnte nicht geladen werden: {image_filename}\")\n",
        "\n",
        "    # Convert image to grayscale\n",
        "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Show image\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(gray_img, cmap='gray')\n",
        "\n",
        "    for idx, pos in enumerate(positions):\n",
        "        x, y, w, h = pos\n",
        "        # Cut out the area of ​​interest\n",
        "        roi = gray_img[y:y+h, x:x+w]\n",
        "\n",
        "        # Apply OCR to the cutout area\n",
        "        results = reader.readtext(roi)\n",
        "\n",
        "        for res in results:\n",
        "            # Coordinates of the recognized text relative to the ROI\n",
        "            (xr1, yr1), (xr2, yr2), (xr3, yr3), (xr4, yr4) = res[0]\n",
        "            # Absolute coordinates in the original image\n",
        "            x1, y1 = x + xr1, y + yr1\n",
        "            x2, y2 = x + xr2, y + yr2\n",
        "            x3, y3 = x + xr3, y + yr3\n",
        "            x4, y4 = x + xr4, y + yr4\n",
        "            # Text and confidence of recognition\n",
        "            det, conf = res[1], res[2]\n",
        "            # View results\n",
        "            plt.plot([x1, x2, x3, x4, x1], [y1, y2, y3, y4, y1], 'r-')\n",
        "            plt.text(x1, y1 - 10, f'{det} [{round(conf, 2)}]', color='red', fontsize=12)\n",
        "            print(f'Digit {idx+1}: Text: {det}, Konfidenz: {conf:.2f}')\n",
        "\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "QqdmT-75Uqa2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Iterating Over Image Files and processing**\n",
        "\n",
        "This step involves the iterative processing of multiple images (meter0001.jpg and meter0002.jpg). For each image file in the list, the complete path to the image is generated by concatenating the directory path (image_folder) with the image filename (image_file). This path is then used to load and process the specific image. A message is printed to the console to indicate which image is being processed, thereby providing clarity on the current operation. Subsequently, the process_image function is called with the constructed image path and the corresponding positional data retrieved from the positions dictionary for the specific image file. This procedure ensures that each image is processed according to its designated regions of interest, as defined by the positional data."
      ],
      "metadata": {
        "id": "5KWCEpAzUthh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate through the image files and process them\n",
        "for image_file in image_files:\n",
        "    image_path = os.path.join(image_folder, image_file)\n",
        "    print(f\"Verarbeite Bild: {image_path}\")\n",
        "    process_image(image_path, positions[image_file])"
      ],
      "metadata": {
        "id": "lDD4gX9dUttv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Image preprocessing - adjustment of digit positioning**"
      ],
      "metadata": {
        "id": "zLYZ7hX6WUZ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Installation**\n",
        "\n",
        "The installation commands facilitate the setup of essential libraries crucial for developing an Optical Character Recognition (OCR) model tailored to recognize digits from images of electricity meters.\n",
        "\n",
        "Firstly, *'opencv-python-headless'* is installed to provide a streamlined version of OpenCV, optimized for server environments or systems without graphical interfaces. This version supports a range of computer vision tasks such as image reading, processing, and feature detection, pivotal for enhancing and analyzing meter images without the need for graphical output.\n",
        "\n",
        "Next, *'easyocr'* is installed, specializing in text extraction from images. This library supports multilingual OCR capabilities and employs efficient algorithms to accurately recognize text, including numerical digits, across diverse environmental conditions. It integrates seamlessly into the project to facilitate the extraction of meter readings from captured images, contributing to the overall functionality of the OCR solution.\n",
        "\n",
        "Finally, *'matplotlib'* is installed to provide comprehensive visualization tools. As a versatile plotting library, matplotlib enables the creation of static, animated, and interactive visualizations. Its integration ensures the project can visually represent processed images, annotate detected digits, and present OCR results in a clear and interpretable manner. Together, these installations establish a robust environment for developing and evaluating an OCR model designed specifically for digit recognition in electricity meter images."
      ],
      "metadata": {
        "id": "qm7VWDshWdRW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Installation of OpenCV\n",
        "!pip install opencv-python-headless\n",
        "\n",
        "# Installation of EasyOCR\n",
        "!pip install easyocr\n",
        "\n",
        "# Installation of Matplotlib\n",
        "!pip install matplotlib"
      ],
      "metadata": {
        "collapsed": true,
        "id": "IzMxJFEyWj6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing Libraries**\n",
        "\n",
        "The essential libaries required in this step are imported for developing an Optical Character Recognition (OCR) model aimed at digit recognition in electricity meter images.\n",
        "\n",
        "*'Cv2 (OpenCV)'* is imported to handle various computer vision tasks such as image reading, manipulation, and processing, which are foundational for enhancing image quality and extracting relevant features from meter images.\n",
        "\n",
        "*'Easyocr'* is imported as a specialized OCR library designed to extract text from images. It supports multiple languages and provides algorithms optimized for accurate character recognition, specifically focusing on digit identification from diverse image backgrounds and conditions.\n",
        "\n",
        "*'matplotlib.pyplot'* is imported to facilitate data visualization tasks, enabling the generation of graphical outputs that aid in visualizing processed images, annotating recognized digits, and presenting OCR results. This library plays a crucial role in visual feedback and evaluation of the OCR model's performance.\n",
        "\n",
        "Lastly, *'os'* is imported to interact with the operating system, allowing for file management tasks such as navigating directories, accessing image files, and ensuring compatibility across different operating environments. Together, these libraries establish a comprehensive framework necessary for implementing and evaluating an OCR solution tailored for digit recognition in electricity meter images."
      ],
      "metadata": {
        "id": "LROJxRvAWnle"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing libraries for image processing, OCR, visualization, and operating system tasks\n",
        "import cv2  # Library for computer vision tasks\n",
        "import easyocr  # Optical Character Recognition (OCR) library\n",
        "import matplotlib.pyplot as plt  # Visualization library\n",
        "import os  # Library for interacting with the operating system"
      ],
      "metadata": {
        "id": "vQvmRtjQW1i1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading OCR Model**\n",
        "\n",
        "This step initializes an Optical Character Recognition (OCR) model by loading the OCR model with English language support. EasyOCR, is a robust OCR library and designed to extract text from images efficiently. By specifying ['en'], the model is tailored to recognize and process text in English. This setup is crucial for accurately identifying and interpreting digits and characters in images, such as in our exmample those from electricity meters. This initialization prepares the model for subsequent text recognition tasks, ensuring it is optimized for the specified language, thus enhancing its accuracy and reliability in extracting textual information from images."
      ],
      "metadata": {
        "id": "DDP9oHd2W5Ny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the OCR model with English language support\n",
        "reader = easyocr.Reader(['en'])"
      ],
      "metadata": {
        "id": "TTAERBBmW5oZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining Image Files**\n",
        "\n",
        "This step is fundamental in organizing and managing the image files that will be used in the digit extraction process, ensuring a structured and efficient workflow, by initializing a list named image_files which contains the filenames of images, specifically 'meter0001.jpg' and 'meter0002.jpg'. These filenames correspond to images of electricity meters. By defining this list, the code prepares for the systematic access and processing of each image in subsequent operations. The list serves as a reference point, enabling the code to iterate through each image file, read the images, and perform OCR (Optical Character Recognition) to extract digits."
      ],
      "metadata": {
        "id": "9N-6fceGW7ea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List of image filenames that should be extracted for digit recognition\n",
        "image_files = [\n",
        "    'meter0001.jpg', 'meter0002.jpg'\n",
        "]"
      ],
      "metadata": {
        "id": "AC86tmgKW7o0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining Digit Positions**\n",
        "\n",
        "In the following step a dictionary named positions is established, with each key representing an image filename and each corresponding value being a list of tuples. These tuples contain the coordinates (x, y, width, height) that define the regions within the respective images where digits are located. For 'meter0001.jpg' and 'meter0002.jpg', the coordinates specify the precise locations and dimensions of regions of interest (ROIs), indicating where the digits are expected to be found. This facilitates targeted image processing and analysis operations on these specific regions."
      ],
      "metadata": {
        "id": "svtsQER2oaAv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary defining the exact positions (x, y, width, height) of digits in each image\n",
        "positions = {\n",
        "'meter0001.jpg': [(9, 2, 74, 169), (99, 2, 68, 144,), (178, 2, 77, 143), (261, 2, 77, 143,), (350, 17, 66, 136,)],\n",
        "'meter0002.jpg': [(6, 5, 50, 93,), (60, 2, 50, 98), (113, 5, 58, 92,), (174, 5, 50, 92,), (229, 6, 48, 91,)]\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "xFaMqcLwoZNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Setting Image Folder Path**\n",
        "\n",
        "Even if the images are already manually loaded in a former step, this path serves to organize and ensure that the images are accessible and correctly loaded.The variable image_folder is defined and the string '/content/' assigned (varies between storage locations). The purpose of this assignment is to specify the directory path where the image files required for further processing are located. By setting this variable, the code ensures a consistent reference point for accessing these images, facilitating file operations such as reading and writing."
      ],
      "metadata": {
        "id": "6WoFK7f3DQmT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory path for the images\n",
        "image_folder = '/content/'  # The image path can vary due to folder location"
      ],
      "metadata": {
        "id": "bthl1ivQDSOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining function for Executing Optical Character Recognition (OCR) and Visualizing Detected Text in Image Regions**\n",
        "\n",
        "The following part with the function process_image is designed to conduct Optical Character Recognition (OCR) on designated regions of an image and to display the outcomes. Initially, the function reads the image from the specified file path using cv2.imread. It then ensures that the image has been successfully loaded; if not, it raises a FileNotFoundError, indicating that the image could not be found or opened.\n",
        "\n",
        "Once the image is successfully loaded, it is displayed using matplotlib. The color space of the image is converted from BGR (Blue, Green, Red) to RGB (Red, Green, Blue) using cv2.cvtColor to ensure accurate color representation in the display. The function then iterates through a list of positions, each representing a rectangular region of interest (ROI) within the image. For each specified position, it extracts the corresponding ROI from the image.\n",
        "\n",
        "The extracted ROI is subjected to OCR using the reader.readtext method, which detects and reads the text contained within this region. The results include bounding box coordinates for each detected text element, which are initially relative to the ROI. These coordinates are adjusted to reflect their absolute position in the context of the entire image.\n",
        "\n",
        "The function then visualizes the results by plotting red bounding boxes around the detected text and annotating these boxes with the recognized text and the associated confidence level. Additionally, it prints the detected text and its confidence level to the console. Finally, the function turns off axis labels and ticks using plt.axis('off') and displays the annotated image with plt.show(), thus providing a comprehensive view of the OCR results and their spatial locations within the original image."
      ],
      "metadata": {
        "id": "Dz_J0HfqXB7H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to perform OCR and display the results\n",
        "def process_image(image_filename, positions):\n",
        "    # Read image\n",
        "    img = cv2.imread(image_filename)\n",
        "\n",
        "    # Make sure the image has loaded\n",
        "    if img is None:\n",
        "        raise FileNotFoundError(f\"Bild konnte nicht geladen werden: {image_filename}\")\n",
        "\n",
        "    # Show image\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "    for idx, pos in enumerate(positions):\n",
        "        x, y, w, h = pos\n",
        "        # Cut out the area of ​​interest\n",
        "        roi = img[y:y+h, x:x+w]\n",
        "\n",
        "        # Apply OCR to the cutout area\n",
        "        results = reader.readtext(roi)\n",
        "\n",
        "        for res in results:\n",
        "            # Coordinates of the recognized text relative to the ROI\n",
        "            (xr1, yr1), (xr2, yr2), (xr3, yr3), (xr4, yr4) = res[0]\n",
        "            # Absolute coordinates in the original image\n",
        "            x1, y1 = x + xr1, y + yr1\n",
        "            x2, y2 = x + xr2, y + yr2\n",
        "            x3, y3 = x + xr3, y + yr3\n",
        "            x4, y4 = x + xr4, y + yr4\n",
        "            # Text and confidence of recognition\n",
        "            det, conf = res[1], res[2]\n",
        "            # View results\n",
        "            plt.plot([x1, x2, x3, x4, x1], [y1, y2, y3, y4, y1], 'r-')\n",
        "            plt.text(x1, y1 - 10, f'{det} [{round(conf, 2)}]', color='red', fontsize=12)\n",
        "            print(f'Digit {idx+1}: Text: {det}, Konfidenz: {conf:.2f}')\n",
        "\n",
        "    plt.axis('off')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "740X9dDkXCED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Iterating Over Image Files and processing**\n",
        "\n",
        "This step involves the iterative processing of multiple images (meter0001.jpg and meter0002.jpg). For each image file in the list, the complete path to the image is generated by concatenating the directory path (image_folder) with the image filename (image_file). This path is then used to load and process the specific image. A message is printed to the console to indicate which image is being processed, thereby providing clarity on the current operation. Subsequently, the process_image function is called with the constructed image path and the corresponding positional data retrieved from the positions dictionary for the specific image file. This procedure ensures that each image is processed according to its designated regions of interest, as defined by the positional data."
      ],
      "metadata": {
        "id": "ZyIH7PDNXFHq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate through the image files and process them\n",
        "for image_file in image_files:\n",
        "    image_path = os.path.join(image_folder, image_file)\n",
        "    print(f\"Verarbeite Bild: {image_path}\")\n",
        "    process_image(image_path, positions[image_file])"
      ],
      "metadata": {
        "id": "zfudneSxXGE7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}